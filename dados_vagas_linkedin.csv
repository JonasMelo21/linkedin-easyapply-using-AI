data_coleta,titulo,empresa,local,link,senioridade,tech_stack,educacao,tipo,soft_skills,cloud,linguas,descricao_raw,cargo_simplificado,senioridade_simplificada,tipo_padronizado
2026-01-04,Data Engineer,CodeRoad Inc,Brazil,https://www.linkedin.com/jobs/view/4345788565,Pleno/S√™nior (M√≠nimo 4+ anos de experi√™ncia),"['Azure Synapse', 'Azure Data Factory', 'Python', 'Databricks', 'Scala', 'SQL', 'Azure', 'Apache Spark']",N/A,"Contrato (Contractor), 100% Remoto (LATAM)","['Comunica√ß√£o', 'Colabora√ß√£o', 'Resolu√ß√£o de Problemas', 'An√°lise']","['Azure', 'Databricks', 'Azure Data Factory', 'Azure Synapse']",['Ingl√™s'],"Sobre a vaga
Data Engineer
The Team
 We are a leading software provider of Item Chain Management solutions to consumer brand, retail and industrial enterprises around the globe. We also provide development services and support to third-party customers across the globe. 
The Data Engineer must be comfortable working virtually as part of one or more customer engagements, with customers located in multiple geographies, and be willing to adjust schedules to meet the specific project's needs.

Location: LATAM (Remote)
Time Zone: Team operates on U.S. East/West Coast hoursHow you‚Äôll make an impact:
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

Minimum requirements:
Advanced English B2-C1 (spoken and written)
4+ years as a Data Engineer experience building processes supporting data transformation, data structures, metadata, dependency, and workload management.
Analytics frameworks and languages, such as: Databricks, Python (Scala is a plus)
Familiar with big data tools: Apache Spark, Data Factory or Synapse. 
Big Data pipelines via Streams and/or Batches.
Experience Relational SQL .
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Experience leading teams nice to have.

What you‚Äôll love:
100% Remote
Contractor position available for Latin American candidates
Holidays Off
Paid Time Off
Health insurance assistance program.
Competitive Pay (USD)
Excellent teamwork and work environment
Training",Data Engineer,Pleno,Remoto
2026-01-04,Azure Data Engineer,MSH,Brazil,https://www.linkedin.com/jobs/view/4326001824,Pleno/S√™nior (3 a 6 anos de experi√™ncia),"['Azure Synapse', 'Azure Data Factory', 'Python', 'Databricks', 'Azure Cosmos DB', 'Azure SQL Database', 'SQL', 'Data Modeling', 'CI/CD', 'Azure']",N/A,Remoto (Full-Time Impl√≠cito),"['Comunica√ß√£o', 'An√°lise de Problemas', 'Trabalho Colaborativo']","['Azure', 'Azure SQL Database', 'Azure Cosmos DB', 'Azure Synapse', 'Databricks']",['Ingl√™s'],"Sobre a vaga
Azure Data Engineer
Location: 100% Remote (EST/CST work hours)

Responsibilities:
Design and develop scalable data pipelines and data integration solutions using Azure Data Factory.
Build, optimize, and maintain data workflows moving structured and semi-structured data into Azure SQL, Cosmos DB, and other Azure storage services.
Develop data transformation logic (SQL, Python preferred) to support reporting, analytics, and downstream applications.
Ensure data quality, reliability, and performance across ingestion and transformation layers.
Collaborate with data analysts, data scientists, and business stakeholders to understand data needs and translate them into scalable engineering solutions.
Monitor pipeline performance, troubleshoot failures, and implement long-term fixes.
Implement best practices for version control, CI/CD, pipeline monitoring, and operational excellence in a cloud environment.
Maintain documentation for data flows, pipeline logic, and architecture.

Qualifications:
3 to 6 years of experience in Data Engineering with hands-on work in Azure cloud environments.
Strong proficiency with Azure Data Factory and SQL-based data transformation.
Experience with Azure Cosmos DB, Azure SQL Database, and related Azure storage technologies.
Strong SQL skills including complex queries, performance tuning, and data modeling concepts.
Experience handling large-scale data sets and building reliable ingestion/processing pipelines.
Solid understanding of data engineering fundamentals including data partitioning, orchestration, error handling, and metadata management.
Excellent analytical and problem-solving capabilities.
Strong communication skills and ability to work cross-functionally.

Preferred Skills:
Experience with Python for ETL/ELT scripting.
Exposure to Azure Synapse, Databricks, or Spark (nice to have but not required).
Understanding of Azure security, networking, and role-based access controls.
Background in data modeling and BI/analytics environments.",Data Engineer,Pleno,Remoto
2026-01-04,Data Engineer,"Pyramid Consulting, Inc",Brazil,https://www.linkedin.com/jobs/view/4343219413,Senior/Especialista (Requer profici√™ncia em 'Expert-level SQL' e experi√™ncia com arquitetura de dados e DevOps),"['Python', 'SQL (Expert Level)', 'Data Lakes', 'Lakehouses', 'Data Hubs', 'Kafka', 'AWS Glue', 'Iceberg', 'Parquet', 'Streaming Architectures', 'Flink', 'dbt', 'Airflow', 'SCD (Slowly Changing Dimensions)', 'Schema Evolution', 'Spark', 'Spark UI (Tuning/Debugging)', 'DevOps', 'CI/CD', 'Code Management']",,,"['Data Governance', 'Data Quality', 'Data Privacy', 'Data Security']",['AWS'],[],"Sobre a vaga
Familiarity with major cloud platforms (AWS)Experience with modern data architectures (data lakes, lakehouses, hubs)Proficiency in ingestion tools (Kafka, AWS Glue) and formats (Iceberg, Parquet)Knowledge of streaming architectures and tools (Kafka, Flink)Strong background in SQL-based frameworks and orchestration tools (dbt, Glue, Airflow). Experience with SCD and schema evolutionFamiliarity with Spark for transformation, streaming, tuning, debugging with Spark UIProficient in Python. Expert-level SQLDemonstrated experience in DevOps practices (code management, CI/CD, deployment)Understanding of governance principles (quality, privacy, security)",,,
2026-01-04,Senior Data Engineer,Qubika,Brazil,https://www.linkedin.com/jobs/view/4342211998,Senior,"['Python', 'SQL', 'Spark', 'Airflow', 'DBT', 'Databricks', 'BigQuery', 'Redshift', 'Delta Lake', 'PostgreSQL', 'S3', 'Parquet', 'Kafka', 'Kinesis', 'Docker', 'Kubernetes', 'Terraform', 'Git', 'ETL/ELT', 'Data Warehousing', 'Distributed Systems', 'CI/CD', 'IaC (Infrastructure as Code)', 'DevOps practices', 'Real-time data streaming (Nice to Have)', 'Machine learning workflows (Nice to Have)']",N/A (Requer 5+ anos de experi√™ncia na √°rea),Data Engineering,"['Colabora√ß√£o', 'Solu√ß√£o de Problemas', 'Trabalho em equipes multifuncionais', 'Comunica√ß√£o (Escrita e Verbal)', 'Proatividade em ambientes din√¢micos', 'Experi√™ncia com consultoria/cliente (Nice to Have)']","['AWS', 'Google Cloud (GCP)', 'Azure']",['Ingl√™s'],"Sobre a vaga
We‚Äôre looking for experienced and passionate Senior Data Engineers to join our growing team and work on cutting-edge data solutions for a variety of clients across industries. If you're someone who thrives in dynamic environments and enjoys building scalable, reliable, and high-performance data infrastructure, we‚Äôd love to hear from you.

What You'll Do
Design, build, and maintain robust data pipelines and ETL processes to support data integration from diverse sources.
Collaborate with data scientists, analysts, and other engineers to define data models, architecture, and best practices.
Optimize data workflows for performance, scalability, and cost-efficiency.
Ensure data quality, security, and governance across systems.
Work with modern cloud platforms to deploy and manage data solutions.
Troubleshoot complex issues and continuously improve data systems.

Tech Stack (varies by project, but may include):
Languages: Python
Database: SQL
Data: Spark, Airflow, DBT, Databricks
Data Storage: BigQuery, Redshift, Delta Lake, PostgreSQL, S3, Parquet
Cloud Platforms: AWS, Google Cloud (GCP), Azure
Tools & Technologies: Kafka, Kinesis, Docker, Kubernetes, Terraform, Git.

What We're Looking For
5+ years of experience in Data Engineering or similar roles.
Strong programming skills in Python and SQL (others are a plus).
Hands-on experience with building and maintaining ETL/ELT pipelines.
Solid understanding of data warehousing concepts and distributed systems.
Experience with cloud services (AWS, GCP, or Azure).
Experience working with Databricks in production environments.
Familiarity with CI/CD, infrastructure as code, and DevOps practices.
Excellent problem-solving skills and ability to work in cross-functional teams.
Strong communication in English (written and verbal).

Nice to Have
Experience in real-time data streaming.
Familiarity with machine learning workflows.
Previous consulting or client-facing experience.

We have multiple open Data Engineering positions with varying technical requirements depending on the project or client. If this description aligns with your experience, we encourage you to apply ‚Äî we might have the perfect fit for you!",,,
2026-01-04,Data Engineer,Insight Global,Brazil,https://www.linkedin.com/jobs/view/4329818405,Mid-S√™nior (2-5+ Anos),"['Python', 'SQL', 'Data Warehouses', 'Relational Databases', 'NoSQL', 'Query Optimization', 'Data Pipelines', 'ETL Tools', 'CI/CD', 'YAML', 'PowerShell', 'Terraform']",,Remoto (CLT),"['Comunica√ß√£o (Verbal e Escrita)', 'Trabalho em Equipe', 'Proatividade T√©cnica']","['Azure', 'Azure Databricks', 'Azure Data Factory (ADF)', 'ADLS (Azure Data Lake Storage)', 'Azure SQL', 'Azure Synapse']",['Ingl√™s'],"Sobre a vaga
This is a fully remote position working for a US client, CLT model and salary range of 16k-20k BRL/mo.

Required Skills & Experience

2-5+ Year of experience in Data Engineering
Use Python or SQL for engineering and scientific calculations
Proven technology champion in working with relational, Data warehouses databases, query authoring (SQL) as well as working familiarity with a variety of databases
Experience/Knowledge in working with NoSQL databases and can create E2E pipelines.
Experienced in building and optimizing complex queries
Proven Experience in working with any one of the data engineering technologies like ADLS, Azure Databricks, ADF, Azure SQL, Synapse

Nice to Have Skills & Experience

Previously created or enhanced CI/CD build and releases pipelines
Experience in working with scripting languages such as YAML, PowerShell, Terraform
Certification in Azure

Job Description

A US client of Insight Global is looking for an Azure Data Engineer to join their team. This person will be assisting the team to create a data warehouse back bone from end-to-end and working with the architect to streamline all processes. Duties will involve creating data pipelines and queries, writing SQL queries from scratch, comparing data, writing analysis, extracting data from existing databases, utilizing Azure Databricks, and working with ETL tools. Both verbal and written communication is a must as this person will be required to work with multiple teams throughout the organization.",,,
2026-01-04,Engenheiro(a) de Dados ‚Äì Databricks,UPBI Data & AI,Brazil,https://www.linkedin.com/jobs/view/4343688056,S√≥lida (Pleno a S√™nior),"['Databricks', 'Spark', 'PySpark', 'SQL', 'Pipelines de Dados', 'ETL/ELT', 'Modelagem de Dados para Analytics (Bronze, Silver, Gold)', 'Delta Lake', 'Data Lake/Lakehouse', 'Orquestra√ß√£o de Dados', 'Governan√ßa e Qualidade de Dados', 'Versionamento (Engenharia de Dados)']",,PJ (Pessoa Jur√≠dica) | H√≠brido,"['Comunica√ß√£o', 'Consultoria T√©cnica', 'Interface com Times de Neg√≥cio', 'Otimiza√ß√£o de Performance', 'Contribui√ß√£o com Boas Pr√°ticas']",['Azure'],[],"Sobre a vaga
Engenheiro(a) de Dados ‚Äì Databricks

Modelo h√≠brido | 3x por semana presencial Bela Vista/SP 2x home office | PJ

A UpBI Data & AI √© uma empresa especializada em Dados, Analytics e Intelig√™ncia Artificial, atuando em projetos estrat√©gicos para grandes clientes. Buscamos um(a) Engenheiro(a) de Dados com forte experi√™ncia em Databricks, para atuar na constru√ß√£o e evolu√ß√£o de plataformas anal√≠ticas modernas em ambientes corporativos complexos.

Responsabilidades:

Projetar, desenvolver e manter pipelines de dados escal√°veis e perform√°ticos utilizando Databricks.
Atuar na ingest√£o, transforma√ß√£o e disponibiliza√ß√£o de dados em ambientes anal√≠ticos e de BI.
Trabalhar com grandes volumes de dados, garantindo qualidade, governan√ßa e confiabilidade das informa√ß√µes.
Desenvolver solu√ß√µes de dados utilizando Spark (PySpark/SQL).
Integrar m√∫ltiplas fontes de dados (estruturadas e semi-estruturadas).
Apoiar times de Analytics, BI e Data Science no consumo dos dados.
Participar ativamente de projetos de clientes, atuando como consultor t√©cnico e parceiro do neg√≥cio.
Contribuir com boas pr√°ticas de engenharia de dados, versionamento, documenta√ß√£o e otimiza√ß√£o de performance.

Requisitos Obrigat√≥rios:

Experi√™ncia s√≥lida como Engenheiro(a) de Dados.
Experi√™ncia pr√°tica com Databricks em ambiente produtivo.
Dom√≠nio de Spark / PySpark e SQL.
Experi√™ncia com modelagem de dados para Analytics (camadas bronze, silver e gold ou conceitos similares).
Conhecimento em pipelines de dados, ETL/ELT.
Experi√™ncia em ambientes de nuvem (preferencialmente Azure).
Capacidade de atuar em consultoria, com boa comunica√ß√£o e interface com times t√©cnicos e de neg√≥cio.
Disponibilidade para atua√ß√£o h√≠brida (3x por semana presencial) no bairro Bela Vista ‚Äì S√£o Paulo/SP.

Requisitos Desej√°veis:

Experi√™ncia com Delta Lake.
Conhecimento em Data Lake / Lakehouse.
Experi√™ncia com ferramentas de orquestra√ß√£o de dados.
Viv√™ncia em projetos de BI, Analytics ou Data Science.
Conhecimentos em boas pr√°ticas de governan√ßa e qualidade de dados.

Modelo de Contrata√ß√£o:

Regime PJ
Modelo h√≠brido: 3 dias presenciais por semana, 2x home office
Local: Bela Vista ‚Äì S√£o Paulo/SP",,,
2026-01-04,Azure Data Engineer,Penta Consulting,Brazil,https://www.linkedin.com/jobs/view/4342917446,Data Architect / S√™nior (Com experi√™ncia comprovada),"['ETL/ELT', 'Data Architecture Design (End-to-End)', 'Big Data Processing', 'Analytics Workflows', 'Machine Learning Concepts', 'Data Modeling', 'Data Warehousing', 'Data Governance', 'Microsoft Fabric', 'DevOps', 'CI/CD', 'Infrastructure-as-Code']",,Remoto no Brasil (Servi√ßos e Workshops),"['Comunica√ß√£o Profissional (Escrita e Oral)', 'Orienta√ß√£o a Clientes Premier Enterprise', 'Habilidade de Workshop/Treinamento']","['Microsoft Azure', 'Azure Data Factory', 'Azure Data Lake', 'Azure Databricks', 'Azure SQL', 'Azure Machine Learning (Azure ML)', 'Azure Foundry']","['Portugu√™s', 'Ingl√™s (Profissional Escrito e Oral)']","Sobre a vaga
We are currently looking for a Portuguese speaking Data Engineer to work across Microsoft Azure solutions in delivering proactive services and workshops to premier enterprise customers in remotely in Brazil. 

Key Responsibilities
Design and implement end-to-end data architecture solutions on Microsoft Azure.
Develop and manage ETL/ELT pipelines using Azure Data Factory.
Architect and optimize Data Lake storage solutions for structured and unstructured data.
Leverage Azure Databricks for big data processing, analytics, and machine learning workflows.
Integrate Azure Machine Learning models into data pipelines and business applications.
Design and maintain Azure SQL databases, ensuring performance, scalability, and security.

Required Skills & Qualifications
Professional English written and oral communication
Proven experience as a Data Architect or similar role in a cloud-first environment.
Strong proficiency in Azure Foundry, Data Factory, Data Lake, Databricks, and Azure SQL.
Experience with Microsoft Fabric and its integration into enterprise data platforms.
Solid understanding of machine learning concepts and deployment in Azure ML.
Expertise in data modeling, data warehousing, and data governance.
Familiarity with DevOps practices, CI/CD pipelines, and infrastructure-as-code.

If you are interested in working with premier enterprise businesses across The Americas, then please apply!

Successful candidates will be contacted within 2 weeks of applying",,,
2026-01-04,Machine Learning Engineer,Canals,Brazil,https://www.linkedin.com/jobs/view/4343344309,S√™nior (Senior-level Machine Learning Engineer),"['Python', 'scikit-learn', 'PyTorch', 'TensorFlow', 'Pandas', 'Spark', 'Data Pipelines Escal√°veis', 'Desenvolvimento e Deploy de Modelos ML em Produ√ß√£o', 'MLOps (Plus)']",,"Full-time, Remoto (Am√©ricas do Norte e do Sul)","['Lideran√ßa T√©cnica e Mentoria', 'Revis√£o de C√≥digo (Code Review) e Feedback Arquitetural', 'Propriedade (Ownership) de Projetos End-to-End', 'Colabora√ß√£o Interdisciplinar', 'Foco em Qualidade, Performance e Reprodutibilidade', 'Trabalho Aut√¥nomo em Ambientes Din√¢micos (Fast-paced)']",[],['Ingl√™s'],"Sobre a vaga
About Canals

Canals is a fully remote, profitable startup transforming the industrial supply chain ($10T industry) with AI. Our platform seamlessly integrates with the systems distributors already use, automating tedious tasks and reducing failure points in moving physical goods across the globe.

We‚Äôre a 70-person team (~45 in engineering), located across North and South America.

The Role

Our customer base is expanding fast, and AI is central to how we scale and deliver value. We‚Äôre looking for a senior-level Machine Learning Engineer who can move quickly while maintaining high quality, owning end-to-end ML pipelines while shaping product features that deliver real-world impact.

What You‚Äôll Do

Design, build, and maintain scalable machine learning models that improve and automate logistics processes for our customers. 
Own projects end-to-end, from problem definition and data exploration to model deployment and monitoring in production. 
Collaborate closely with engineering teams to align ML work with customer needs and deliver features that drive business value. 
Serve as a technical leader and mentor within the ML area, reviewing code and ensuring best practices for reproducibility, quality, and performance. 
Evaluate and implement tools and frameworks to improve our ML infrastructure and workflows. 
Help shape the future of Canals as we continue scaling with our customers. 

What You'll Bring

Senior-level experience building and deploying machine learning models in production environments. 
Experience designing scalable data pipelines and working with large datasets. 
Comfort taking ownership of projects and ensuring models deliver real, measurable customer value. 
Strong Python skills with knowledge of ML frameworks (e.g., scikit-learn, PyTorch, TensorFlow) and data tools (e.g., Pandas, Spark). 
Ability to guide and unblock others, providing thoughtful code reviews and architectural feedback. 
Experience working independently in a fast-paced, product-focused environment. 
Previous experience in high-growth startups or small teams is a plus. 
Familiarity with MLOps practices and tools is a plus. 

Why Join Canals

We're profitable: stability without the chaos of venture pivots. 
Real-world impact: your work improves global supply chains, saving customers time and reducing waste. 
Strong engineering culture: we invest in quality and documentation to keep moving fast sustainably. 
Culture of ownership: moving fast while putting quality first
Remote-first, flexible work environment across North and South America. 
Stellar product-market fit with tons of customer love
All star team with diverse backgrounds to collaborate with and learn from

Canals.ai is an equal opportunity employer. In addition to EEO being the law, it is a policy that is fully consistent with our principles. All qualified applicants will receive consideration for employment without regard to status as a protected veteran or a qualified individual with a disability, or other protected status such as race, religion, color, national origin, sex, sexual orientation, gender identity, genetic information, pregnancy or age.",,,
2026-01-04,Machine Learning Engineer,JetBridge AI,Brazil,https://www.linkedin.com/jobs/view/4346860266,Senior IC (Individual Contributor) / Machine Learning Engineer,"['Python', 'Pandas', 'NumPy', 'scikit-learn', 'SQL', 'XGBoost', 'LightGBM', 'Predictive Modeling', 'Anomaly Detection', 'Time Series Analysis', 'Forecasting', 'Feature Engineering', 'Model Evaluation', 'Model Interpretability (SHAP-style analysis)']",,Full-Time,"['Independ√™ncia', 'Forte Intui√ß√£o Estat√≠stica', 'Colabora√ß√£o (Parceria com times de produto e analytics)', 'Orienta√ß√£o a Insights Acion√°veis']",[],['Ingl√™s'],"Sobre a vaga
Build a drug access platform for a fast-growing, profitable health-tech company, where your machine learning models directly detect and prevent drug-access failures, helping millions of insured Americans actually receive the medications their benefits promise.

We‚Äôre hiring a Machine Learning Engineer to work on applied predictive modeling and anomaly detection across complex, high-volume healthcare program data. This is a hands-on, senior IC role focused on turning messy real-world signals into clear, actionable insights that improve medication access across the U.S. healthcare system.

Unlike academic or toy ML problems, the work here sits directly in the flow of patient access: identifying failures in drug affordability programs, surfacing non-obvious breakdowns in benefit usage, and enabling teams to intervene before patients abandon treatment.

What You‚Äôll Do
- Build predictive models (forecasting, time series, trend analysis) on real-world program and financial data.
- Design anomaly / outlier detection to surface risks, inefficiencies, and non-obvious patterns.
- Own feature engineering, model evaluation, and interpretability (feature importance, SHAP-style analysis).
- Work end-to-end from exploration ‚Üí modeling ‚Üí business-facing insights.
- Partner with product and analytics teams to turn models into decisions.

Must-Have
- 4‚Äì7 years as ML Engineer or Applied Data Scientist
- Strong predictive modeling + anomaly detection background
- Hands-on experience with messy, high-volume financial or program data
- Strong statistical intuition (not just fitting models)
- Python with Pandas / NumPy / scikit-learn
- Comfortable operating independently as a senior IC

Nice to Have
- U.S. healthcare-adjacent data (insurance, benefits, copay, utilization)
- Experience in compliance-aware environments (HIPAA-constrained data)
- Translating models into dashboards, reports, or exec-ready insights
- XGBoost / LightGBM, solid SQL

Explicitly Not Required
- MLOps ownership or DevOps work
- Managing teams
- Pharma biology expertise

Video question:
""What‚Äôs the most valuable engineering decision you made in the last 12 months? Why was it valuable?""

Submit your video here: 
https://sendspark.com/request/JB/kdoi6s0yugc8xuhe91f8gvg9a9c9njl2

*Applications that submitted a 60-second video answering the question will be given the highest priority. Only our most Senior HR Manager will watch your video and delete it afterward. We review 100% of the videos submitted.",,,
2026-01-04,Machine Learning Engineer,Mindbody,Brazil,https://www.linkedin.com/jobs/view/4221533508,Mid-Level,"['Python', 'SQL', 'Machine Learning (ML)', 'Desenvolvimento e Deploy de Modelos em Produ√ß√£o', 'MLOps', 'Engenharia de Dados (Data Engineering)', 'Data Pipelines', 'C√≥digo Limpo, Test√°vel e Escal√°vel']",,N/A (Presume-se Full-Time),"['Comunica√ß√£o Excelente (Escrita e Verbal)', 'Curiosidade Intelectual', 'Pr√≥-atividade/Bias for Action', 'Foco em Resultados (Results-Driven)', 'Intui√ß√£o de Neg√≥cios (Business Intuition)', 'Colabora√ß√£o e Peer Reviews']",[],['Ingl√™s'],"Sobre a vaga
At Playlist, life's richest moments happen when people step away from screens to move, connect, explore, and play. We're building the definitive platform for intentional living, connecting people with inspiring experiences in fitness, wellness, and beyond. With popular brands like Mindbody and ClassPass, Playlist empowers businesses and individuals, making it effortless for aspirations to become actions. Join us in reshaping technology's role to foster meaningful, real-world connections.

Mindbody equips wellness entrepreneurs with technology to support thriving businesses and create exceptional experiences. Innovation and curiosity drive our culture, connecting businesses and individuals through cutting-edge solutions. Join us if you're passionate about enhancing wellness through technology.

The Role You‚Äôll Play

Develop and deploy production-ready machine learning models across a wide range of applications. 
Monitor and maintain the performance of models in production environments. 
Engineer and integrate data from multiple sources to fuel training pipelines, predictions, and business insights. 
Collaborate with Product Managers to ensure solutions align with customer impact and business goals. 
Write clean, testable, and scalable code while contributing to shared design documents and engineering discussions. 
Conduct peer reviews to uphold engineering quality and share knowledge across the team. 
Stay current with emerging technologies in ML, data engineering, and AI. 

Experience You Bring

2+ years of hands-on experience building and deploying machine learning models in production. 
Proficiency in Python and SQL, with a strong understanding of data manipulation and model pipelines. 
Excellent communication skills, both written and verbal, with the ability to explain technical work in a clear and thoughtful way. 
Intellectual curiosity and a bias for action‚Äîyou‚Äôre excited to explore, experiment, and iterate. 
Strong business intuition and the ability to balance technical rigor with customer outcomes. 
A results-driven mindset‚Äîyou care more about solving the problem than using the flashiest method. 
A proactive approach to identifying and solving complex challenges‚Äîboth independently and in collaboration. 

Have we piqued your curiosity?

Sound like the role for you? We‚Äôd love to hear from you! Even if you‚Äôre not 100% sure about potential fit, we still encourage you to apply. We‚Äôre looking for the right person, not the perfect series of checkboxes.

Playlist is an Equal Opportunity Employer. We highly value diversity at our company and encourage people of all different backgrounds, experiences, abilities and perspectives to apply. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or other protected characteristics.

By entering your email and phone number and submitting your application, you consent to receive emails, calls and SMS about your application and other roles at Playlist, including by auto-dialer. Message and data rates may apply. Opt-out or text STOP to cancel at any time. If you are a California resident or reside outside the United States then by submitting your application you confirm that you have read, understood, agree and - where applicable - grant your prior, free, informed and express consent for the processing of your personal information, including sensitive personal information, as described in our California Applicant Privacy Notice or International Applicant Privacy Notice (as applicable).

Note: This description outlines key responsibilities but isn‚Äôt intended to cover every task or duty. Additional responsibilities may be assigned as needed to support the team and business goals.",,,
2026-01-04,AI/ML Engineer Specialist - Freelance Project,"Meridial Marketplace, by Invisible",Brazil,https://www.linkedin.com/jobs/view/4334622167,Mid-level/Experienced (M√≠nimo de 2 anos),"['Python', 'Pandas', 'NumPy', 'scikit-learn', 'PyTorch', 'TensorFlow', 'Spark', 'Machine Learning (ML)', 'Deep Learning', 'NLP', 'Reinforcement Learning', 'Time Series Analysis', 'Regression Models', 'Classification Models', 'Recommendation Systems', 'Model Deployment (Prototype to Production)', 'Model Evaluation', 'Experimental Design', 'Data Debugging', 'Clean Code']",N/A (Foco em 2+ anos de experi√™ncia pr√°tica),Contrato (Contractor),"['Colabora√ß√£o', 'Comunica√ß√£o com Stakeholders', 'Resolu√ß√£o de Problemas (Ambiguidade)', 'Tradu√ß√£o de Insights T√©cnicos', 'Proatividade em Inova√ß√£o']","['GCP', 'AWS', 'Cloud Environments (similar)', 'Databricks (Plus)']",['Ingl√™s'],"Sobre a vaga
What You‚Äôll Do

Design and deliver machine learning solutions that combine modern research with practical deployment. Working across industries and use cases, contribute to building robust models that power client-facing tools and internal platforms.

Develop End-to-End ML Models: Design, train, and evaluate models across supervised, unsupervised, and reinforcement learning domains tailored to diverse problem areas.
Collaborate on Real-World Solutions: Work with engineers and data scientists to integrate models into deployable systems operating in production environments.
Client-Focused Problem Solving: Engage with stakeholders to frame ambiguous problems, explore solution paths, and translate technical insights into practical outcomes.
Explore, Iterate, Validate: Lead the exploration and analysis of datasets using tools like Pandas, NumPy, and Spark to inform model design and performance evaluation.
Research-Driven Innovation: Identify opportunities to adapt state-of-the-art methods and productionize them to deliver measurable impact.

Target Profile

2+ years of hands-on experience building and deploying machine learning models using modern techniques.
Proven ability to take models from prototype to production in Python-based workflows.
Experience working directly with stakeholders to clarify requirements and inform project outcomes.

Technical Expertise

Strong proficiency in Python and commonly used ML/data libraries (Pandas, NumPy, scikit-learn, PyTorch, TensorFlow, etc).
Familiarity with different model classes (e.g., regression, classification, recommendation, time series, NLP, reinforcement learning).
Experience working with large-scale datasets using distributed tools such as Spark.
Comfort navigating cloud environments (GCP, AWS, or similar); Databricks experience is a plus.
Solid grasp of experimental design, model evaluation, and data debugging practices.
Ability to write clean, modular, testable code in collaborative environments.

We offer a pay range of $30+ per hour, with the exact rate determined after evaluating your experience, expertise, and geographic location. Final offer amounts may vary from the pay range listed above. As a contractor you‚Äôll supply a secure computer and high‚Äëspeed internet; company‚Äësponsored benefits such as health insurance and PTO do not apply.

Important

All candidates must pass an interview as part of the contracting process.",,,
2026-01-04,AI Engineer,Dry Ground AI,Brazil,https://www.linkedin.com/jobs/view/4350965651,"Pleno/S√™nior (2+ anos de experi√™ncia, com responsabilidades de mentoria e lideran√ßa t√©cnica)","['Python', 'TensorFlow', 'PyTorch', 'Scikit-learn', 'Hugging Face Transformers', 'LLMs (Large Language Models)', 'GPT', 'BERT', 'Generative AI', 'Transformer-based architectures', 'LangChain', 'LangGraph', 'LangSmith', 'LangFuse', 'n8n', 'ElevenLabs', 'OpenAI', 'Stable Diffusion', 'REST APIs', 'Processamento de Linguagem Natural (NLP)', 'Automa√ß√£o de workflows', 'Data pipelines (Preprocessing e Feature Engineering)', 'Prompt Engineering', 'Context Engineering', 'MLOps (Model versioning, CI/CD, Monitoring) (Preferencial)', 'Microsoft Copilot Studio (Preferencial)', 'PowerApps (Preferencial)', 'PowerAutomate (Preferencial)', 'Reinforcement learning (Preferencial)', 'GANs (Generative Adversarial Networks) (Preferencial)', 'Edge AI deployments (Preferencial)', 'Apache Spark (Preferencial)', 'Ray (Preferencial)']",N/A (Foco em experi√™ncia pr√°tica),Remoto (Full-time impl√≠cito),"['Versatilidade', 'Pensamento Sist√™mico (Systems thinking)', 'Colabora√ß√£o Interfuncional', 'Lideran√ßa T√©cnica', 'Mentoria', 'An√°lise de dados', 'Habilidade para traduzir problemas de neg√≥cio em solu√ß√µes t√©cnicas']",['Familiaridade com plataformas de AI/ML baseadas em Nuvem'],[],"Sobre a vaga
Position Overview
 We are seeking a versatile and highly skilled AI Engineer to join our fast-growing Full-Stack AI Solutions company. This role blends the expertise of building cutting-edge AI/ML models with the practical know-how of automation and agentic system integrations. You will design, develop, deploy, and optimize intelligent solutions that leverage the power of generative AI, automation platforms, and agent-based systems to enhance client operations, streamline workflows, and deliver measurable results.
 This is a unique opportunity to work across a diverse range of technologies‚Äîfrom fine-tuning transformer models to building real-world AI-powered automation stacks. If you‚Äôre passionate about pushing the boundaries of AI while creating real value through systems thinking and practical implementation, this role is for you.
 
Key Responsibilities
 AI/ML Development
Design, build, and deploy machine learning and generative AI models for custom use cases.
Fine-tune and optimize large language models (e.g., GPT, BERT) using frameworks like Hugging Face Transformers.
Conduct ongoing research to stay ahead of advancements in AI/ML, including LLMs, generative AI, and transformer-based architectures.
Develop data pipelines for preprocessing, feature engineering, and model training.
Test, validate, and monitor model performance in real-world scenarios; iterate for reliability and accuracy.
Collaborate with cross-functional teams to embed AI into products, platforms, and services.
Mentor junior engineers and contribute to technical leadership.
 Automation & Agentic Systems
Design, implement, and maintain automation workflows using tools such as:
LangChain, LangGraph, LangSmith, LangFuse n8n, ElevenLabs, and CMS integrations.
Engineer system-to-system integrations using APIs to enable intelligent process automation.
Apply prompt and context engineering techniques to enhance the performance of conversational AI tools.
Implement prompt management and QA processes for agents and assistants.
Explore and deploy Microsoft Copilot Studio, PowerApps, and PowerAutomate solutions (preferred but not required).
Continuously evaluate emerging AI and automation tools and assess their applicability in client use cases.
Collaborate with clients and internal teams to scope, deliver, and maintain agentic and automation solutions aligned with business goals.
 
Qualifications
 Required
2+ years of hands-on experience in AI/ML development, including training and deploying models in production.
Strong programming skills in Python, with proficiency in frameworks such as TensorFlow, PyTorch, Scikit-learn, and Hugging Face Transformers.
Experience working with AI tools like Langchain, OpenAI, or Stable Diffusion.
Practical experience with automation platforms and AI agent builders (as listed above).
Deep understanding of machine learning algorithms, neural networks, and NLP concepts.
Proficiency in using REST APIs for tool and platform integrations.
Familiarity with cloud-based AI/ML platforms.
Strong analytical skills and the ability to translate business problems into technical AI/automation solutions.
 Preferred
Experience working with Agentic AI frameworks, voice automation, and prompt tuning systems.
Exposure to MLOps best practices, including model versioning, CI/CD, and monitoring.
Knowledge of reinforcement learning, GANs, or edge AI deployments.
Familiarity with distributed computing frameworks such as Spark or Ray.
Background in AI agency workflows and client-facing solution delivery.
 
Work Environment & Benefits

Competitive salary and performance-based incentives.
Flexible work environment: Remote-first.
Collaborative, innovation-driven culture with a commitment to personal and professional growth.
Opportunity to work at the forefront of AI innovation across industries and verticals.",,,
2026-01-04,Machine Learning Engineer,Oowlish,Brazil,https://www.linkedin.com/jobs/view/4329186678,Pleno/S√™nior (Especialista),"['Machine Learning', 'Intelig√™ncia Artificial (IA)', 'Desenvolvimento de Solu√ß√µes de IA', 'Modelagem de Machine Learning', 'Valida√ß√£o de Modelos', 'Implementa√ß√£o em Produ√ß√£o (MLOps)', 'Monitoramento de Desempenho de Modelos', 'Versionamento']","Forma√ß√£o em Engenharia, Ci√™ncia da Computa√ß√£o, Ci√™ncia de Dados ou √°reas relacionadas",Remoto,"['Capacidade Anal√≠tica', 'Resolu√ß√£o de Problemas', 'Autonomia', 'Orienta√ß√£o a Resultados', 'Proatividade', 'Boa Comunica√ß√£o', 'Trabalho em Equipe']",[],['Ingl√™s'],"Sobre a vaga
Venha fazer parte do nosso time na Oowlish!

Est√° em busca de uma oportunidade para elevar sua carreira ao pr√≥ximo n√≠vel no cen√°rio tecnol√≥gico? A Oowlish, uma das empresas de desenvolvimento de software que mais cresce na Am√©rica Latina, procura por especialistas em tecnologia para refor√ßar nosso time din√¢mico e multicultural.

Integrar a Oowlish significa mais do que apenas ser parte de uma equipe: √© abra√ßar uma cultura inovadora e solid√°ria, colaborando com clientes renomados dos Estados Unidos e Europa em projetos digitais desafiadores. Como uma empresa reconhecida por seu excelente ambiente de trabalho, priorizamos o aprendizado cont√≠nuo, o crescimento profissional e o impacto significativo em escala global ‚Äî tudo isso em conjunto!

Valorizamos a flexibilidade e promovemos um ambiente de trabalho que respeita o equil√≠brio entre vida pessoal e profissional. Aqui, voc√™ pode gerir seu pr√≥prio tempo e espa√ßo, contribuindo para o nosso sucesso coletivo enquanto usufrui de uma rotina que se adapta ao seu estilo de vida. Se voc√™ √© apaixonado(a) por tecnologia e busca um ambiente de trabalho estimulante e remoto, a Oowlish √© o seu lugar!

Sobre a Posi√ß√£o:

Estamos em busca de um(a) Machine Learning Engineer / AI Engineer para desenvolver, implementar e manter solu√ß√µes de intelig√™ncia artificial e aprendizado de m√°quina alinhadas aos objetivos do neg√≥cio. Esta posi√ß√£o √© ideal para profissionais que gostam de trabalhar com dados, modelos e aplica√ß√µes pr√°ticas de IA, transformando ideias em solu√ß√µes reais e escal√°veis.

Voc√™ atuar√° em colabora√ß√£o com equipes de dados, produto e engenharia, participando de todo o ciclo de vida das solu√ß√µes de machine learning ‚Äî desde a concep√ß√£o e modelagem at√© a implementa√ß√£o em ambientes produtivos e o monitoramento cont√≠nuo de desempenho. Procuramos algu√©m com perfil anal√≠tico, autonomia e foco em resultados, capaz de atuar em um ambiente din√¢mico e em constante evolu√ß√£o.

Responsabilidades:


Projetar, desenvolver e validar modelos de machine learning
Implementar solu√ß√µes de IA em ambientes produtivos
Trabalhar em conjunto com equipes de dados e produto para entender requisitos de neg√≥cio
Monitorar desempenho, qualidade e confiabilidade dos modelos em produ√ß√£o
Realizar ajustes e melhorias cont√≠nuas nos modelos
Documentar processos, modelos e decis√µes t√©cnicas
Garantir boas pr√°ticas de desenvolvimento e versionamento



Requisitos:


Forma√ß√£o em Engenharia, Ci√™ncia da Computa√ß√£o, Ci√™ncia de Dados ou √°reas relacionadas
Experi√™ncia pr√©via com modelos de machine learning ou solu√ß√µes de IA
Forte capacidade anal√≠tica e de resolu√ß√£o de problemas
Boa comunica√ß√£o e habilidade para trabalho em equipe
Perfil proativo, aut√¥nomo e orientado a resultados



Diferenciais:


Experi√™ncia com projetos de IA em produ√ß√£o
Conhecimento de boas pr√°ticas de modelagem, valida√ß√£o e monitoramento de modelos
Ingl√™s intermedi√°rio ou avan√ßado



Benefits & Perks:

Hor√°rio flex√≠vel;

Remunera√ß√£o competitiva de acordo com a experi√™ncia;

Planos de carreira para possibilitar amplo crescimento na empresa;

Projetos internacionais;

Programa de Ingl√™s Oowlish (T√©cnico e Conversa√ß√£o);

Oowlish Fitness com Total Pass;

Jogos e Competi√ß√µes;

We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us.",,,
2026-01-04,Artificial Intelligence Engineer,Foursys,Brazil,https://www.linkedin.com/jobs/view/4343774626,,"['Python', 'Machine Learning', 'Intelig√™ncia Artificial (IA)', 'Pandas', 'Flask', 'RAG (Retrieval-Augmented Generation)', 'ETL', 'Integra√ß√£o de dados', 'MLflow', 'OpenTelemetry', 'LangGraph', 'Scikit-learn', 'Visual Basic (Diferencial)', 'Metodologia √Ågil', 'Scrum']",,H√≠brido,"['Boa comunica√ß√£o', 'Trabalho em equipe', 'Proatividade', 'Agilidade', 'Capacidade anal√≠tica', 'Senso de responsabilidade', 'Facilidade para atuar em ambientes colaborativos e din√¢micos']",[],[],"Sobre a vaga
A Foursys √© um time apaixonado por inova√ß√£o, design e transforma√ß√£o digital. Somos globais, somos GPTW.

Na Foursys, celebramos a diversidade e acreditamos que s√£o as diferentes ideias e perspectivas que nos enriquecem. Portanto, sua cor, religi√£o, g√™nero, ra√ßa, nacionalidade, idade, origem, identidade de g√™nero, defici√™ncia ou orienta√ß√£o sexual n√£o s√£o barreiras para se juntar √† nossa equipe.
#VemSerFoursys!

Todas as nossas vagas est√£o abertas para Pessoas com Defici√™ncia (PCD). Caso voc√™ se enquadre ou conhe√ßa algu√©m com o perfil, a Foursys √© a empresa ideal!

Que tal se juntar a n√≥s e se tornar um(a) #FourTalent?

Habilidades T√©cnicas:
Python para desenvolvimento de solu√ß√µes em IA;
Machine Learning;
Intelig√™ncia Artificial aplicada a produtos e servi√ßos;
Pandas para manipula√ß√£o e an√°lise de dados;
Flask para desenvolvimento de APIs;
RAG (Retrieval-Augmented Generation);
ETL e Integra√ß√£o de dados;
MLflow para versionamento e rastreabilidade de modelos;
OpenTelemetry para observabilidade;
LangGraph;
Scikit-learn;
Visual Basic (diferencial).

Habilidades Comportamentais:

Boa comunica√ß√£o e trabalho em equipe;
Proatividade e agilidade;
Capacidade anal√≠tica e senso de responsabilidade;
Facilidade para atuar em ambientes colaborativos e din√¢micos.

Metodologias:

√Ågil / Scrum.

Modelo de Trabalho

H√≠brido ‚Äì 3 dias presenciais por semana
üìç Local: S√£o Paulo ‚Äì SP

Benef√≠cios | Clube da Four

Assist√™ncia m√©dica;
VR e VA flex√≠vel;
Gympass e Wellz;
Parceria com o SESC;
Descontos em restaurantes;
Descontos em cursos t√©cnicos e de ensino superior;
Descontos em escolas e plataformas de idiomas.

E a√≠, aceita o desafio?

Ent√£o conclua sua candidatura e #VemSerFoursys!
Boa sorte!",,,
2026-01-04,Senior Data Scientist,Teramind,Brazil,https://www.linkedin.com/jobs/view/4348482735,Senior Data Scientist,"['Python', 'SQL', 'TensorFlow', 'PyTorch', 'Scikit-learn', 'XGBoost', 'Spark', 'BigQuery', 'ML Pipelines (End-to-End)', 'Modelagem de Comportamento', 'Predi√ß√£o Comportamental', 'Detec√ß√£o de Anomalias', 'Risk Scoring', 'Transformer Architectures', 'Otimiza√ß√£o de Modelos (Lat√™ncia, Efici√™ncia)', 'Estat√≠stica', 'Infer√™ncia Causal', 'Design Experimental', 'A/B Testing']","Mestrado em disciplina quantitativa (Estat√≠stica, Engenharia, Ci√™ncia da Computa√ß√£o) ou experi√™ncia equivalente",Remoto,"['Inova√ß√£o', 'Resourcefulness', 'Autonomia', 'Colabora√ß√£o', 'Adaptabilidade', 'Experimenta√ß√£o R√°pida', 'Resolu√ß√£o de Ambiguidade', 'Parceria com Produto e Engenharia']",[],['Ingl√™s'],"Sobre a vaga
About Teramind

Teramind is the leading platform for user behavior analytics, serving multiple use cases from insider risk mitigation to business process optimization. With our comprehensive suite of solutions, organizations gain unprecedented visibility into user activities while enhancing security, optimizing productivity, and ensuring compliance. Trusted by Fortune 500 companies and businesses of all sizes across industries, our innovative platform helps organizations protect sensitive data, maximize workforce performance, and create safer, more efficient digital workplaces. Through real-time monitoring and advanced analytics, we enable businesses to safeguard their most sensitive information while optimizing employee productivity in both in-office and remote work environments.

Our Core Values

At Teramind, our values drive everything we do. We embrace innovation as a fundamental principle, constantly pushing boundaries to improve our products, streamline processes, and enhance customer experiences. We foster resourcefulness by empowering our team members with the autonomy and confidence to solve problems independently while providing collaborative support when needed. As a globally inclusive organization, we celebrate diversity and create an adaptable work culture where respect and collaboration thrive across our international teams. Above all, we are committed to excellence, delivering the highest quality in every aspect of our work and consistently exceeding expectations in service to our clients and each other.

About The Role

Teramind is on a mission to reinvent how organizations understand work. With millions of behavioral signals flowing through our platform, we're unlocking a new era of intelligent workforce analytics - from predictive insights to behavior modeling and ML-powered decision-making. We're building a brand-new data science organization to make this vision real. And we're hiring a Senior Data Scientist who wants to build the models, pipelines, and intelligent systems that power the future of analytics at Teramind. If you thrive at the intersection of deep technical work, rapid experimentation, and real product impact - this is your role.

What You‚Äôll Do

‚Ä¢ Design and implement ML models for behavior prediction, anomaly detection, and risk scoring
‚Ä¢ Develop and fine-tune transformer-based models
‚Ä¢ Optimize models for production deployment‚Äîbalancing accuracy, latency, and resource efficiency 
‚Ä¢ Build end-to-end pipelines from raw behavioral signals to production-ready features
‚Ä¢ Partner with product and engineering to translate business problems into data science solutions
‚Ä¢ Run rigorous experiments‚ÄîA/B tests, causal inference, statistical validation‚Äîto measure real impact
‚Ä¢ Prototype rapidly, iterate based on customer feedback, and ship models that scale
‚Ä¢ Contribute to the technical foundations and best practices of a growing DS function

What You Bring

‚Ä¢ Deep hands-on expertise in Python, SQL, and ML framework (TensorFlow, PyTorch, Scikit-learn, XGBoost)
‚Ä¢ 5+ years of experience shipping ML models to production with measurable product or business impact
‚Ä¢ Strong fundamentals in statistics, causal inference, and experimental design
‚Ä¢ Experience with transformer architectures
‚Ä¢ Familiarity with model optimization for production constraints
‚Ä¢ Comfort working in ambiguity‚Äîscoping problems, finding data, and driving to solutions independently
‚Ä¢ Experience with large-scale data processing (Spark, BigQuery, or similar) is a plus
‚Ä¢ Master's degree in a quantitative discipline such as Statistics, Engineering, Computer Science, or equivalent practical experience


Benefits

This is a remote job. Work from anywhere! We‚Äôve been thriving as a fully-remote team since 2014. To us, remote work means flexibility and having truly diverse, global teams.

Additionally:

‚Ä¢ Collaboration with a forward-thinking team where new ideas come to life, experience is valued, and talent is incubated.
‚Ä¢ Competitive salary
‚Ä¢ Career growth opportunities
‚Ä¢ Flexible paid time off
‚Ä¢ Laptop reimbursement
‚Ä¢ Ongoing training and development opportunities

About our recruitment process

We don‚Äôt expect a perfect fit for every requirement we‚Äôve outlined. If you can see yourself contributing to the team, we want to hear your story. You can expect up to 3 interviews. In some scenarios, we‚Äôre able to streamline the process to have minimal rounds. Director-level roles and above should expect a more thorough process, with multiple rounds of interviews.

All roles require reference and background checks

Teramind is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration without regard to race, age, religion, color, marital status, national origin, gender, gender identity or expression, sexual orientation, disability, or veteran status.

We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us.",,,
2026-01-04,DATA SCIENTIST PL,Stone,Brazil,https://www.linkedin.com/jobs/view/4348862746,Data Scientist (Requer experi√™ncia pr√©via em An√°lise/Ci√™ncia de Dados e Modelagem),"['Python', 'SQL', 'Pandas', 'Scikit-learn', 'XGBoost', 'Modelagem Estat√≠stica', 'Algoritmos de Aprendizado de M√°quina', 'Treinamento Supervisionado', 'Treinamento N√£o Supervisionado', 'Engenharia e Sele√ß√£o de Features', 'An√°lise Univariada/Bivariada/Multivariada', 'Redu√ß√£o de Dimensionalidade', 'Feature Scaling', 'Balanceamento de Dados', 'Tunning de Hiperpar√¢metros', 'Avalia√ß√£o e Compara√ß√£o de Modelos', 'Testes A/B (Experimentos)', 'Detec√ß√£o de Fraudes', 'Detec√ß√£o de Anomalias', 'Redes Neurais (Diferencial)', 'NLP (Diferencial)', 'Sistemas de Recomenda√ß√£o (Diferencial)', 'S√©ries Temporais (Diferencial)']",,,"['Esp√≠rito de Dono (Own It)', 'Autonomia', 'Proatividade', 'Perfil Anal√≠tico Forte', 'Capacidade Investigativa', 'Data Storytelling (Transformar an√°lises em narrativas claras)', 'Colabora√ß√£o (Team Play)', 'Transpar√™ncia (No Bullshit)', 'Orienta√ß√£o ao Cliente']","['AWS', 'GCP', 'Ecossistemas de Big Data (Ex: Databricks, Spark)']",[],"Sobre a vaga
Nossa cultura:
Por aqui, vivemos nossa cultura no dia a dia, guiados por esses 5 pilares:

‚ö°Own It: Ter esp√≠rito de dono te faz conquistar a liberdade. Valorizamos a autonomia e a proatividade, somos respons√°veis pelo o que entregamos e queremos sempre evoluir o nosso neg√≥cio.

üé¢Live the Ride: Fa√ßa. Feito √© melhor que perfeito. Aprendemos com os erros e encaramos desafios como oportunidades de aprendizado.

üé§No Bullshit: Agir com simplicidade. Somos pessoas pr√°ticas, sinceras e gostamos de feedbacks. Sabemos que √†s vezes vamos errar e contamos com essa transpar√™ncia para evoluirmos.

ü§ùTeam Play: Se quer ir r√°pido, v√° sozinho(a). Se quer ir longe, trabalhe em equipe. √â sempre poss√≠vel aprender com as outras pessoas e a colabora√ß√£o √© a chave do sucesso.

üíöThe Reason: O cliente n√£o tem raz√£o, ele √© a raz√£o. Nos motivamos a enxergar o impacto do nosso trabalho na vida do cliente, √© vendo que melhoramos a vida dele que sabemos que fizemos uma boa entrega.

O time de Preven√ß√£o a Fraudes:

A √°rea de Preven√ß√£o a Fraudes √© respons√°vel por proteger os nossos clientes e nossa empresa contra riscos associados √† fraude nas mais diversas frentes, desempenhando um papel central na identifica√ß√£o e mitiga√ß√£o de potenciais amea√ßas. √â uma √°rea multidisciplinar, composta por times de opera√ß√µes, produto, an√°lise e ci√™ncia de dados, e √© formada por pessoas investigativas e com forte perfil anal√≠tico. Temos o prop√≥sito de desenvolver mecanismos que permitam reduzir a poss√≠vel perda financeira gerada por fraude ou risco de neg√≥cio, buscando tamb√©m a melhor rela√ß√£o risco-retorno entre decis√µes autom√°ticas (modelos e regras) e decis√µes da mesa de opera√ß√µes. O time de preven√ß√£o a fraudes KYC atua diretamente nestes dois pilares. No processo de credenciamento, verificamos identidades, avaliamos perfis de risco e monitoramos constantemente para detectar atividades suspeitas por meio de an√°lises extensiva de dados. Al√©m disso, tamb√©m analisamos continuamente o ciclo de vida do cliente, buscando garantir que o o cliente √© ele mesmo, prezando pelo bom uso de nossos produtos.


Como √© Ser Uma Pessoa DATA SCIENTIST:
Buscamos uma pessoa para se juntar ao time de Estrat√©gia e Modelagem, com a miss√£o de usar ci√™ncia de dados para construir barreiras inteligentes contra fraudadores no nosso processo de credenciamento (KYC) e ao longo de todo o ciclo de vida do cliente. Seu trabalho ser√° essencial para garantir um crescimento seguro, combinando an√°lises profundas e modelagem preditiva para tomar decis√µes de risco-retorno mais eficientes, sempre buscando a melhor experi√™ncia para os bons clientes. Algumas das atividades do dia a dia incluem:
Analisar e explorar grandes volumes de dados (internos e externos) para descobrir padr√µes de fraude, identificar vulnerabilidades e gerar insights para novas estrat√©gias de preven√ß√£o;
Desenvolver, implementar e otimizar modelos estat√≠sticos e algoritmos de aprendizado de m√°quina para prever, detectar e mitigar atividades fraudulentas;
Formular e validar hip√≥teses sobre poss√≠veis vetores de ataque, participando da cria√ß√£o e an√°lise de experimentos (como testes A/B) para medir o impacto de novas regras e modelos;
Identificar e avaliar continuamente os potenciais pontos de melhoria nos processos de KYC e riscos associados a diferentes tipos de atividades de clientes, desenvolvendo estrat√©gias para mitig√°-los; - Formula√ß√£o de hip√≥teses sobre poss√≠veis cen√°rios de fraude, condu√ß√£o de experimentos controlados para validar e iterar sobre as estrat√©gias de preven√ß√£o;
Colaborar ativamente com analistas de risco, engenheiros de dados, desenvolvedores e gerentes de produto para construir e integrar solu√ß√µes de ponta a ponta;
Acompanhamento cont√≠nuo das tend√™ncias e padr√µes de fraude emergentes, adaptando as estrat√©gias conforme necess√°rio.

O que esperamos de voc√™:

Experi√™ncia pr√©via em an√°lise / ci√™ncia de dados;
Experi√™ncia em times de estrat√©gia / intelig√™ncia de preven√ß√£o a fraudes ou √°reas correlatas;
Conhecimento consolidado em fundamentos de estat√≠stica, infer√™ncia e modelagem matem√°tica;
Habilidade de transformar an√°lises complexas em narrativas claras e acion√°veis (data storytelling) para apresentar resultados e auxiliar na tomada de decis√£o;
Capaz de desenvolver modelos t√≠picos de machine learning utilizando t√©cnicas de treinamento supervisionado e n√£o supervisionado, com conhecimento de suas etapas (engenharia e sele√ß√£o de features, an√°lise univariada/bivariada/multivariada, redu√ß√£o de dimensionalidade, feature scaling, balanceamento de dados, tunning de hiperpar√¢metros, etc.);
Capaz de utilizar t√©cnicas de avalia√ß√£o e compara√ß√£o de modelos;
Profici√™ncia em Python para an√°lise de dados e modelagem (ex: Pandas, Scikit-learn, XGBoost) e SQL para manipula√ß√£o de grandes volumes de dados;

 O Que aumentam suas chances: 

Experi√™ncia espec√≠fica com preven√ß√£o a fraudes no processo de credenciamento/KYC em adquirentes, fintechs, bancos ou ecommerces;
Especializa√ß√£o em temas espec√≠ficos da √°rea de machine learning (redes neurais, NLP, sistemas de recomenda√ß√£o, s√©ries temporais, detec√ß√£o de anomalias, clusteriza√ß√£o, etc.);
Experi√™ncia com ecossistemas de Big Data e plataformas de nuvem (ex: Databricks, Spark, AWS, GCP).

Nossos benef√≠cios:
ü©∫ Plano de Sa√∫de e Odontol√≥gico

üè•Hospital Virtual Verde dispon√≠vel 24 horas por dia, 7 dias por semana, de forma r√°pida e pr√°tica

ü•ó Vale Refei√ß√£o e/ou Vale Alimenta√ß√£o

üå¥ Conv√™nio SESC

üïó Hor√°rio flex√≠vel

‚úè Benef√≠cio Educa√ß√£o - Plataforma interna com acesso a diversos livros, podcasts, treinamentos e v√≠deo aulas visando o autodesenvolvimento (Studa e Biblioteca StoneCo)

üí™ Gympass

üë∂ Aux√≠lio Creche - para crian√ßas at√© 5 anos e 11 meses

üí∞ Sal√°rio Fixo + PLR (quando preenchidos os requisitos)

üíö Seguro de Vida

üöóVale Transporte (exclusivo para vagas presenciais)

Etapas do Processo Seletivo:
‚úçInscri√ß√£o: Aqui voc√™ come√ßa a sua jornada conosco. Fique tranquilo(a), nosso time analisar√° as informa√ß√µes do seu perfil e entrar√° em contato em breve. Boa sorte!

üìûEntrevistas com o time de People: Este √© o momento de nos conhecermos! Voc√™ ter√° um papo inicial com nosso time de recrutamento, com o objetivo de conhecer nossa cultura, estrutura e o desafio que est√° sendo proposto.

üéØAvalia√ß√£o T√©cnica: Nesta etapa vamos nos aprofundar nas suas hard skills! Geralmente essa avalia√ß√£o √© composta por dois papos ou um papo mais o desafio, com o objetivo de avaliar habilidades e compet√™ncias t√©cnicas espec√≠ficas para a vaga. Al√©m de te apresentar poss√≠veis pares e lideran√ßa.

‚úÖCheck de Cultura: Nossa cultura √© muito importante e est√° sempre presente no dia a dia! Aqui, voc√™ ter√° um papo com uma das nossas pessoas guardi√£s da cultura, com o objetivo de nos conhecer e garantir que nossas cren√ßas, nosso jeito de pensar e nossa vis√£o de futuro est√£o alinhadas com o que voc√™ acredita e busca vivenciar.

üèÅFeedback: Uma de nossas for√ßas √© a franqueza. Por isso, independente do resultado, iremos compartilh√°-lo com voc√™ e alinhar os pr√≥ximos passos.


E a√≠? Curtiu? Ent√£o, n√£o deixa de se inscrever e #VemSerStone üíöüöÄ

Aqui na Stone Co., valorizamos e procuramos as melhores pessoas para nos ajudar a melhorar a vida das pessoas empreendedoras do Brasil. Nosso sonho √© do tamanho do universo e, se voc√™ se identifica com o nosso prop√≥sito, venha constru√≠-lo com a gente! Caso queira saber mais:



Confira nossa trilha de carreira para o time de tecnologia, a Star Trail Tech.
Vem conhecer nosso time e aprender muito no nosso canal do Youtube.
Temos v√°rios artigos no Medium.
N√£o deixe de dar uma conferida no nosso Github.
Confira aqui as diretrizes do nosso C√≥digo de √âtica.
E pra ficar por dentro de todas as novidades, √© s√≥ nos seguir no Twitter.




*Al√©m das vagas afirmativas, todas as vagas Stone tamb√©m s√£o destinadas a pessoas com defici√™ncia.",,,
2026-01-04,Senior Data Scientist,Tata Consultancy Services,Brazil,https://www.linkedin.com/jobs/view/4346790735,Senior Data Scientist,"['Python', 'Machine Learning', 'Deep Learning', 'GenAI', 'LLMs', 'Prompt Engineering', 'multimodal models', 'TensorFlow', 'PyTorch', 'Pandas', 'NumPy', 'Scikit-learn', 'SQL', 'bancos de dados relacionais', 'bancos de dados n√£o-relacionais', 'MLOps (Best Practices)', 'CI/CD', 'Data Pipelines', 'manuseio de grandes volumes de dados']","Bacharelado em Ci√™ncia da Computa√ß√£o, Engenharia, Estat√≠stica, Matem√°tica, ou √°reas relacionadas.",,"['Lideran√ßa T√©cnica', 'Mentoria de Equipe', 'Colabora√ß√£o', 'Tradu√ß√£o de necessidades de neg√≥cio (Stakeholder collaboration)', 'Documenta√ß√£o']","['AWS', 'S3', 'Lambda', 'SageMaker', 'EC2', 'IAM']",[],"Sobre a vaga
Come to one of the biggest IT Services companies in the world!! Here you can transform your career! 
 Why to join TCS? Here at TCS we believe that people make the difference, that's why we live a culture of unlimited learning full of opportunities for improvement and mutual development. The ideal scenario to expand ideas through the right tools, contributing to our success in a collaborative environment. 
 We are looking for Senior Data Scientist who wants to learn and transform his career. 
 In this role you will: (responsibilities) 
 SAFe We are looking for a Senior Data Scientist with extensive experience in Python, Machine Learning, and advanced knowledge of AWS components to lead data analysis projects and develop scalable solutions. Technologies such as Deep Learning and GenAI will be considered advantages.
Experience with Deep Learning (TensorFlow, PyTorch). Knowledge in GenAI (LLMs, Prompt Engineering, APIs such as OpenAI, HuggingFace). Experience with multimodal models.
Education: Bachelor's degree in Computer Science, Engineering, Statistics, Mathematics, or related fields. 
 Experience: 
 Advanced programming in Python (Pandas, NumPy, Scikit-learn). 
 Development and implementation of Machine Learning models at scale. 
 Solid experience with AWS components (S3, Lambda, SageMaker, EC2, IAM). 
 Experience in technical leadership or team mentoring.
Additional skills:
 Handling large volumes of data.
 Knowledge of SQL and relational/non-relational databases.
 Best practices in MLOps and CI/CD for models.
 Lead the design, development, and implementation of Machine Learning models for complex applications.
 Build robust and scalable data pipelines, ensuring quality and performance.
 Define architecture and integrate solutions with AWS services (S3, Lambda, SageMaker, EC2, IAM).
 Act as a technical reference, guiding teams and ensuring best practices.
 Collaborate with stakeholders to translate business needs into data-driven solutions.
 Document processes and promote standards for versioning, testing, and deployment.
Python, Machine Learning; components AWS
What can you expect from us? 
 ‚Ä¢ Professional development and constant evolution of your skills, always in line with your interests. 
‚Ä¢ Opportunities to work outside Brazil 
‚Ä¢ A collaborative, diverse and innovative environment that encourages teamwork. 
 What do we offer? 
 TCS Benefits ‚Äì Brazil: 
Health insurance 
Dental Plan 
Life insurance 
Transportation vouchers 
Meal/Food Voucher 
Childcare assistance 
Gympass 
TCS Cares ‚Äì free 0800 that provides psychological assistance (24 hrs/day), legal, social and financial assistance to associates 
Partnership with SESC 
Reimbursement of Certifications 
Free TCS Learning Portal ‚Äì Online courses and live training 
International experience opportunity 
Discount Partnership with Universities and Language Schools 
Bring Your Buddy ‚Äì By referring people you become eligible to receive a bonus for each hire 
TCS Gems ‚Äì Recognition for performance 
Xcelerate ‚Äì Free Mentoring Career Platform 
 At TATA Consultancy Services we promote an inclusive culture, we always work for equity. This applies to Gender, People with Disabilities, LGBTQIA+, Religion, Race, Ethnicity. All our opportunities are based on these principles. We think of different actions of inclusion and social responsibility, in order to build a TCS that respects individuality. Come to be a TCSer! 

#Buildingonbelief 

ID: 10470412",,,
2026-01-04,Data Scientist,Ascendion,Brazil,https://www.linkedin.com/jobs/view/4328096527,Senior (6-7 years experience),"['Data Science', 'Machine Learning (ML)', 'Artificial Intelligence (AI)', 'LLMs', 'Generative AI', 'Python', 'LLM Output Evaluation (Manual/Automated)', 'LLM-as-a-Judge', 'LLM-as-a-Jury', 'ChatGPT', 'Claude', 'Mistral', 'AI Evaluation Metrics', 'Quality Frameworks', 'LLMOps', 'AI Monitoring']",,Contract,"['Strong communication skills', 'collaborative mindset', 'Interest in AI safety', 'reliability', 'responsible AI processes']","['AWS', 'Lambda', 'EC2', 'S3', 'SQS', 'SNS']",[],"Sobre a vaga
About Ascendion
Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.

Ascendion | Engineering to elevate life

We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:
Build the coolest tech for the world‚Äôs leading brands
Solve complex problems ‚Äì and learn new skills
Experience the power of transforming digital engineering for Fortune 500 clients
Master your craft with leading training programs and hands-on experience.

Experience a community of change-makers!
Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.

About the Role

Job Title: Data Scientist
Contract Type: Contract in Brazil
Office model - Remote

We‚Äôre looking for a Senior Data Scientist focused on evaluating LLM-based products. The role is all about making sure AI outputs are high-quality, accurate, safe, and useful, using a mix of human evaluation and LLM-based evaluation approaches (LLM-as-a-Judge and LLM-as-a-Jury). You‚Äôll work closely with SMEs, product, and engineering teams to build and scale evaluation frameworks that help improve AI products. 

What You‚Äôll Do:

Review and evaluate LLM outputs for quality, accuracy, safety, and relevance.
Work with SMEs on manual and human-in-the-loop evaluations.
Use LLMs to evaluate other LLMs (LLM-as-a-Judge / LLM-as-a-Jury) 
Define simple evaluation criteria and scoring guidelines.
Analyze results and share clear feedback with product and engineering teams.
Help improve evaluation processes and best practices over time.

What We‚Äôre Looking For:

6-7 years of experience in Data Science, ML, or AI roles.
Strong experience with LLMs and Generative AI.
AWS: Core AWS - Lambda, EC2, S3, SQS, SNS, etc. 
Hands-on experience evaluating LLM outputs (manual or automated).
Solid Python skills for analysis and automation.
Experience with LLMs like ChatGPT, Claude, Mistral, or similar.
Strong communication skills and a collaborative mindset.

Nice to Haves:

Experience with AI evaluation metrics or quality frameworks.
Familiarity with LLMOps or AI monitoring.
Interest in AI safety, reliability, and responsible AI processes.",,,
2026-01-04,Data Scientist,IFIT Solutions,Brazil,https://www.linkedin.com/jobs/view/4346569953,S√™nior,"['PySpark (Avan√ßado)', 'Estat√≠stica Aplicada', 'A/B Testing', 'Experiment Design', 'Modular Coding', 'Scalable Code']",,"PJ, Remoto, Long Term","['Comunica√ß√£o', 'Capacidade de Articula√ß√£o', 'Proatividade', 'Business Acumen (Tradeoffs)']",[],['Ingl√™s (Avan√ßado)'],"Sobre a vaga
Currently looking for a Data Scientist with experience in :

Advanced pyspark skills with experience building modular code, must have the ability to build scalable code, rather than one-off analyses and experiment notebooks
Professional experience using statistics in a business setting, measuring AB tests with code, not via a tool. Should be able to identify missing steps in a measurement approach or experiment design, articulate the gaps, and make a proposal to his/her team members. Also should be able to recognize the tradeoffs between ideal experiment design and the realities of launching an experiment in the business context.
Advanced English
Remote
Long Term
PJ contract

Send cv in english",,,
2026-01-04,Especialista de Intelig√™ncia de Dados,Privalia,Brazil,https://www.linkedin.com/jobs/view/4350692627,Especialista,"['Power BI', 'Tableau', 'Google Data Studio', 'SQL', 'Banco de dados relacionais', 'Python', 'R', 'Excel avan√ßado', 'Google Sheets avan√ßado', 'Big Data', 'Green Belt', 'Lean Six Sigma', 'KPIs', 'OKRs', 'Sistemas ERP/Produ√ß√£o', 'Automa√ß√£o de processos de dados', 'Governan√ßa de dados']","Ensino superior completo (Administra√ß√£o, Engenharia, Estat√≠stica, Economia, Ci√™ncia de Dados). P√≥s-gradua√ß√£o/MBA em Business Intelligence, Analytics ou Gest√£o de Opera√ß√µes (Diferencial).",Presencial,"['Pensamento Estrat√©gico', 'Comunica√ß√£o e Parceria Interfuncional', 'Foco em Efici√™ncia Operacional', 'Apoio √† Tomada de Decis√£o']",[],[],"Sobre a vaga
Como Especialista de Intelig√™ncia de Dados voc√™ ser√° respons√°vel pela atua√ß√£o de forma estrat√©gica na gest√£o e an√°lise de dados da √°rea de Produ√ß√£o. 
Ser√° respons√°vel por transformar informa√ß√µes em insights acion√°veis, garantindo maior efici√™ncia operacional, apoio √† tomada de decis√£o e desenvolvimento de solu√ß√µes que fortale√ßam a intelig√™ncia do neg√≥cio.

Responsabilidades e atribui√ß√µes: 
Estruturar, consolidar e analisar dados de performance da √°rea de Produ√ß√£o;
Desenvolver relat√≥rios, dashboards e pain√©is de acompanhamento (KPIs e OKRs);
Apoiar a gest√£o com insights estrat√©gicos para melhoria de processos e aumento de produtividade;
Garantir a qualidade, confiabilidade e governan√ßa das informa√ß√µes gerenciais;
Mapear indicadores cr√≠ticos, propor planos de a√ß√£o e acompanhar evolu√ß√£o de resultados;
Automatizar processos de coleta, tratamento e disponibiliza√ß√£o de dados;
Atuar em parceria com diferentes √°reas para integrar informa√ß√µes e alinhar estrat√©gias.

Requisitos e qualifica√ß√µes: 
Ensino superior completo em Administra√ß√£o, Engenharia, Estat√≠stica, Economia, Ci√™ncia de Dados ou √°reas correlatas;
P√≥s-gradua√ß√£o ou MBA em Business Intelligence, Analytics ou Gest√£o de Opera√ß√µes ser√° considerado diferencial;
Certifica√ß√µes em Power BI, Tableau ou Google Data Studio (Diferencial);
Certifica√ß√£o em SQL, Big Data, Data Analytics ou afins (Diferencial);
Green Belt/Lean Six Sigma para melhoria de processos (Diferencial);
Dom√≠nio em ferramentas de visualiza√ß√£o de dados (ex.: Power BI, Tableau, Looker ou similares);
Excel/Google Sheets avan√ßado;
Conhecimento em SQL e banco de dados relacionais;
Desej√°vel experi√™ncia com Python ou R para an√°lise de dados;
Familiaridade com sistemas de ERP/Produ√ß√£o ser√° diferencial.

O que oferecemos?
Al√©m de um clima descontra√≠do, sem pol√≠tica de dress code e total open space, compartilhamos de alguns outros benef√≠cios que trazem qualidade de vida e muita felicidade:

ü©∫Assist√™ncia M√©dica
Sa√∫de em primeiro lugar! Oferecemos um plano m√©dico completo pra voc√™ e seus dependentes se sentirem cuidados e tranquilos.

ü™• Assist√™ncia Odontol√≥gica
Sorriso bonito e saud√°vel? Temos! Com acesso f√°cil a cuidados odontol√≥gicos de qualidade.

üçΩÔ∏è Vale Refei√ß√£o ou Alimenta√ß√£o
Voc√™ escolhe: restaurante ou mercado. O importante √© ter liberdade e equil√≠brio na sua alimenta√ß√£o.

üöê Vale Transporte
Facilitamos sua mobilidade para que voc√™ chegue ao trabalho com tranquilidade.

üõçÔ∏è Desconto Privali@
Descontos especiais em marcas e produtos incr√≠veis. Porque voc√™ tamb√©m merece aproveitar!

üéÅ VP Club
Nosso clube de vantagens exclusivo, com benef√≠cios pensados especialmente pra quem √© #Pri

üèãÔ∏è Wellhub
Acesso a academias, est√∫dios e atividades f√≠sicas. Porque cuidar do corpo tamb√©m √© essencial.

üßò Zenklub
Sa√∫de emocional importa ‚Äî e muito. Conte com apoio psicol√≥gico e conte√∫dos de bem-estar sempre que precisar.

üéâ Happy Day (folga no anivers√°rio)
Seu dia, do seu jeito. Aqui, anivers√°rio √© com a tarde livre pra comemorar como quiser.

üêæ Pet Day
Em datas especiais, seu pet √© nosso convidado! Um dia leve e cheio de carinho no escrit√≥rio.

üçª Happy Friday
Encerramos a semana com leveza e integra√ß√£o. Um momento para relaxar e se conectar com o time.

üßñServi√ßos no ambiente de trabalho
Manicure, snacks, barbeiro, quick massage, gin√°stica laboral, frutas, food truck (o famoso Corujinha!) e muito mais pra deixar sua rotina mais pr√°tica e gostosa.

O que voc√™ est√° esperando para se juntar a n√≥s?
Challenge yourself! #TodayCanBeSpecial",,,
2026-01-04,Engenheiro de Dados - Remoto,Getronics,Brazil,https://www.linkedin.com/jobs/view/4347474422,,"['Programa√ß√£o', 'Tratamento de Dados', 'Python', 'PySpark', 'SQL', 'HUE', 'Hive', 'Spark', 'SparkML', 'NIFI', 'DB2', 'MySQL', 'Oracle', 'Dbeaver', 'Modelagem de Dados', 'Erwin', 'Git']",,Remoto,[],[],[],"Sobre a vaga
A Getronics √© l√≠der global em solu√ß√µes de tecnologia, com uma equipe de mais de 4.000 colegas em 22 pa√≠ses, fornecendo servi√ßos abrangentes de ponta a ponta em todo o mundo. Temos o compromisso de oferecer um atendimento excepcional ao cliente, para permitir que eles se concentrem em seus principais pontos fortes, enquanto confiam suas necessidades de TI √† Getronics. Temos uma oportunidade incr√≠vel para voc√™ se juntar √† nossa equipe, na seguinte vaga: Engenheiro de Dados - Remoto.

O que oferecemos a voc√™:
- Assist√™ncia m√©dica sem desconto para titulares
- Assist√™ncia odontol√≥gica sem desconto para titulares
- Cart√£o flex tanto para alimenta√ß√£o quanto refei√ß√£o
- Aux√≠lio home office para vaga remota
- Vale transporte para posi√ß√µes presenciais ou h√≠bridas
- Aux√≠lio creche
- Seguro de vida
- Parceria com institui√ß√µes de ensino
- Parceria com escolas de idiomas
- Programa de subs√≠dio para aulas de ingl√™s
- Programa de indica√ß√µes: pr√™mio para indica√ß√µes bem-sucedidas
- Licen√ßa maternidade estendida de 180 dias e a licen√ßa paternidade de 20 dias
- Treinamento completo fornecido como parte de um processo de indu√ß√£o robusto, incluindo oportunidades de desenvolvimento cont√≠nuo com nossa plataforma de aprendizado online NorthStar, LinkedIn Learning e Udemy, que possui mais de 80.000 cursos dispon√≠veis
- GetVibes - nosso programa de escuta ativa que nos permite conectar e ouvir feedback de todos os colegas, e como empresa, trabalhamos juntos para elaborar planos de a√ß√£o para melhorar e desenvolver continuamente a Getronics!

O que esperar desta posi√ß√£o:
Projeto de desenvolvimento e melhorias em sistemas banc√°rios.

O que esperamos de voc√™:
Conhecimentos:
‚Ä¢ Programa√ß√£o;
‚Ä¢ Tratamento de Dados.
Linguagens:
‚Ä¢ Python;
‚Ä¢ PySpark;
‚Ä¢ SQL.
Ferramentas:
Big Data:
‚Ä¢ HUE;
‚Ä¢ Hive;
‚Ä¢ Spark (SparkML);
‚Ä¢ NIFI.
Banco de Dados:
‚Ä¢ DB2;
‚Ä¢ MySQL;
‚Ä¢ Oracle;
‚Ä¢ Dbeaver (Ferramenta de Consulta).
‚Ä¢ Modelagem de Dados (Erwin)
‚Ä¢ Versionamento de c√≥digo (Git)

O que fazer em seguida:
Caso voc√™ seja a pessoa que estamos procurando, aguarde nosso contato para te conhecermos melhor e siga as instru√ß√µes durante o processo seletivo. Se voc√™ gostaria de fazer alguma pergunta sobre nossas vagas, sobre a Getronics como empresa ou qualquer outra coisa, por favor, n√£o hesite em entrar em contato. A equipe de RH estar√° dispon√≠vel no e-mail recrutamento@getronics.com.",,,
